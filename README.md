# ğŸš— Vehicle MLOps Project

## ğŸŒŸ Overview

This project demonstrates a **complete MLOps workflow** for an end-to-end Machine Learning system on vehicle insurance system related data.
It covers everything from **data ingestion** â†’ **validation** â†’ **transformation** â†’ **model training & evaluation** â†’ **deployment on AWS with CI/CD**.

The goal is to **showcase modern MLOps practices** with cloud integration, automated pipelines, monitoring, and scalable deployment.

---

## ğŸ”‘ Key Features

* ğŸ“¦ **Project Template Automation** with Python scripts (`template.py`)
* ğŸ§© **Local Package Management** via `setup.py` & `pyproject.toml`
* ğŸ **Virtual Environment & Dependencies** management with Conda + pip
* ğŸƒ **MongoDB Atlas** integration for scalable cloud database storage
* ğŸ“ **Logging & Exception Handling** modules
* ğŸ“Š **EDA & Feature Engineering Notebooks** for exploration
* ğŸ“¥ **Data Ingestion Pipeline** connected to MongoDB
* âœ… **Data Validation & Transformation** with schema checks
* ğŸ¤– **Model Training, Evaluation, and Registry**
* â˜ï¸ **AWS S3 Integration** for model storage and versioning
* ğŸ³ **Dockerized Application** ready for deployment
* ğŸ”„ **CI/CD Pipeline** with GitHub Actions + Self-Hosted Runner on EC2
* ğŸŒ **Deployed Flask App** accessible via public IP on port 5000

---

## ğŸ› ï¸ Tech Stack

* **Programming Language**: Python 3.11
* **Database**: MongoDB Atlas
* **Machine Learning**: Scikit-learn, Pandas, NumPy
* **Cloud**: AWS (IAM, S3, ECR, EC2)
* **Containerization**: Docker
* **Orchestration & CI/CD**: GitHub Actions, Self-Hosted Runner
* **App Framework**: Flask
* **Version Control**: Git + GitHub

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ .github/workflows/        # GitHub Actions CI/CD workflows
â”œâ”€â”€ artifacts/                # Generated artifacts (ignored in git)
â”œâ”€â”€ notebook/                 # EDA, MongoDB demo notebooks
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ components/           # ML pipeline components
â”‚   â”œâ”€â”€ configuration/        # DB & AWS configuration
â”‚   â”œâ”€â”€ data_access/          # Data ingestion from MongoDB
â”‚   â”œâ”€â”€ entity/               # Config & artifact entities
â”‚   â”œâ”€â”€ aws_storage/          # S3 push/pull utilities
â”‚   â””â”€â”€ utils/                # Helper functions
â”œâ”€â”€ static/                   # Web app static files
â”œâ”€â”€ templates/                # HTML templates for Flask app
â”œâ”€â”€ app.py                    # Flask application entry point
â”œâ”€â”€ setup.py                  # Local package setup
â”œâ”€â”€ pyproject.toml            # Dependency/project metadata
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Dockerfile                # Docker image definition
â””â”€â”€ template.py               # Auto-create project structure
```

---

## âš™ï¸ Workflow

### 1. **Environment Setup**

```bash
conda create -n vehicle python=3.11 -y
conda activate vehicle
pip install -r requirements.txt
```

### 2. **MongoDB Integration**

* Setup **MongoDB Atlas** cluster & user
* Connect using environment variable:

```bash
export MONGODB_URL="mongodb+srv://<username>:<password>@cluster-url"
```

### 3. **Pipeline Stages**

* **Data Ingestion** â†’ Fetch from MongoDB, store as DataFrame
* **Data Validation** â†’ Schema checks (`schema.yaml`)
* **Data Transformation** â†’ Feature engineering & preprocessing
* **Model Training** â†’ Train ML model
* **Model Evaluation** â†’ Evaluate with drift detection
* **Model Pusher** â†’ Upload best model to AWS S3

### 4. **Deployment**

* Build Docker image & push to AWS ECR
* Deploy container on AWS EC2 instance
* Expose Flask app on port 5000

---

## ğŸš€ CI/CD Pipeline

* **GitHub Actions** â†’ Triggers on every push/commit
* **Self-Hosted Runner on EC2** â†’ Runs jobs in AWS
* **Secrets Management** â†’ AWS keys stored in GitHub Secrets
* **ECR + Docker** â†’ Stores container images
* **EC2 Deployment** â†’ App served at `<public-ip>:5000`

---

## ğŸ“Š Architecture Diagram

```mermaid
flowchart LR
    A[MongoDB Atlas] -->|Data Ingestion| B[Data Pipeline]
    B --> C[Data Validation]
    C --> D[Data Transformation]
    D --> E[Model Training]
    E --> F[Model Evaluation]
    F --> G[AWS S3 - Model Registry]
    G --> H[Dockerized App]
    H --> I[CI/CD with GitHub Actions]
    I --> J[Deployment on AWS EC2]
```

---

âœ¨ This project is built to **showcase modern MLOps practices** and demonstrate real-world deployment of ML pipelines with scalable cloud integration.

---

